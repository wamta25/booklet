As our compute capacity grows, science simulations are not only becoming bigger, but more complex. Simulations are carried out at multiple scales and using multiple kinds of physics at once. Boundaries are irregular, grids are irregular, computational domains can be dynamic and complex. In such scenarios, the ideal way to parallelize often cannot be statically determined. At the same time, hardware is becoming more heterogeneous and difficult to program. Increasingly, scientists are turning to asynchronous, dynamic parallelism in order to make the best use of increasingly challenging hardware. As a result, numerous frameworks, platforms, and specialized languages have sprung up to answer this need.

The objectives of this workshop are to bring together experts in asynchronous many-task frameworks, developers of science codes, performance experts, and hardware vendors to discuss the state-of-the-art techniques needed to program, analyze, benchmark, and profile these codes to achieve maximum performance possible from modern machines. This workshop will promote a dialogue between these communities, and help identify challenges and opportunities for advancement in all the disciplines they represent.

\section*{Organizing committee}
\begin{itemize}
\item Patrick Diehl, Louisiana State University (USA)
\item Pedro Valero-Lara, Oak Ridge National Laboratory (USA)
\item George Bosilca, NVIDIA (USA)
\item Joseph Schuchart, University of Tennessee, Knoxville (USA)
\end{itemize}

\section*{Scientific committee}
\begin{itemize}
\item Alex Aiken, Stanford (USA)
\item Erwin Laure, Max Planck Computing \& Data Facility (Germany)
\item Christoph Junghans, Los Alamos National Laboratory (USA)
\item Bryce Adelstein Lelbach, NVIDIA (USA)
\item  Laxmikant V. Kale, University of Illinois at Urbana-Champaign (USA)
\item Brad Chamberlain, HPE and University of Washington (USA)
\end{itemize}

\section*{Technical program chair}

\begin{itemize}
\item Patrick Diehl, Louisiana State University (USA)
\item Pedro Valero-Lara, Oak Ridge National Laboratory (USA)
\item George Bosilca, NVIDIA (USA)
\item Joseph Schuchart, University of Tennessee, Knoxville (USA)
\end{itemize}

\section*{Technical program }

\begin{itemize}
\item Brad Richardson, Sourcery Institute (USA)
\item Kevin Huck, University of Oregon (USA)
\item Dirk Pflüger, University of Stuttgart (Germany)
\item Metin H. Aktulga, Michigan State University (USA)
\item Huda Ibeid, Intel
\item Dirk Pleiter, KTH Royal Institute of Technology (Sweden)
\item Didem Unat, Koç University (Turkey)
\item Keita Teranishi, Sandia National Laboratories (USA)
\item Gregor Daiß, University of Stuttgart (Germany)
\item Najoude Nader, Louisiana State University (USA)
\item Weile Wei, Lawrence Berkeley National Laboratory (USA)
\item Jeff Hammond, NVIDIA (Finland)
\item Hartmut Kaiser, Louisiana State University (USA)
\item J. Ram Ramanujam, Louisiana State University (USA)
\item Steven R. Brandt, Louisiana State University (USA)
\item Narasinga Rao Miniskar, Oak Ridge National Laboratory (USA)
\item Markus Rampp, Max Planck Computing and Data Facility (Germany)
\item Sumathi Lakshmiranganatha, Los Alamos National Laboratory (USA)
\item Nikunj Gupta, Amazon (USA)
\item Jonas Posner, University of Kassel (Germany)
\end{itemize}


\section*{Logistics}
\begin{itemize}
\item Parsa Aminim, Halpern-Wight Inc. (USA)
\item Joseph Schuchart and Thomas Herault, University of Tennessee, Knoxville (USA)
\end{itemize}

