Python is the de-facto language for software development in artificial intelligence (AI).
Commonly used libraries, such as PyTorch and TensorFlow, rely on parallelization built into their BLAS backends to achieve speedup on CPUs.
However, only applying parallelization in a low-level backend can lead to performance and scaling degradation.
In this work, we present a novel way of binding task-based C++ code built on the asynchronous runtime model HPX to a high-level Python API using pybind11.
We develop a parallel Gaussian process (GP) library as an application.
The resulting Python library GPRat combines the ease of use of commonly available GP libraries with the performance and scalability of asynchronous runtime systems.
We evaluate the performance on a mass-spring-damper system, a standard benchmark from control theory, with varying number of regressors (features). Results show almost no overhead when binding the asynchronous HPX code using pybind11.
Compared to GPyTorch and GPflow, GPRat shows superior scaling on up to 64 cores on an AMD EPYC 7742 CPU for training.
Furthermore, our library achieves a prediction speedup of up to factor 7.63 over GPyTorch and 25.25 over GPflow.
If we increase the number of features from eight to 128, we observe speedups of up to factor 29.62 and 21.19, respectively.
These results showcase the potential of using asynchronous tasks within Python-based AI applications.
